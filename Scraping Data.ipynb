{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this notebook I'll scraping the data that i will use for this project. The data is the **List of Walt Disney Pictures Films** from wikipedia, the website can be found at: [Walt Disney Pictures Films](https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from bs4 import BeautifulSoup as bs # library use to do the web scraping\n",
    "import requests # library to make the requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The goal of this step is create a list of dictionaries with the title movie and some informations about the movie, this information can be found on the page in the right side below the image*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first it'll be made for one example, then it'll iterate for all movies\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Dumbo\" # i'll be taking the Dumbo movie as example\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "dumbo_page = bs(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Dumbo',\n",
       " 'Directed by': ['Ben Sharpsteen',\n",
       "  'Norman Ferguson',\n",
       "  'Wilfred Jackson',\n",
       "  'Jack Kinney'],\n",
       " 'Produced by': 'Walt Disney',\n",
       " 'Story by': ['Joe Grant', 'Dick Huemer'],\n",
       " 'Based on': ['Helen Aberson'],\n",
       " 'Starring': ['Edward Brophy',\n",
       "  'Herman Bing',\n",
       "  'Sterling Holloway',\n",
       "  'Verna Felton',\n",
       "  'Cliff Edwards',\n",
       "  'James Baskett',\n",
       "  'Nick Stewart',\n",
       "  'Hall Johnson'],\n",
       " 'Narrated by': 'John McLeish',\n",
       " 'Music by': ['Frank Churchill', 'Oliver Wallace'],\n",
       " 'Production company': 'Walt Disney Productions',\n",
       " 'Distributed by': 'RKO Radio Pictures',\n",
       " 'Release date': ['October 23, 1941 ( 1941-10-23 ) (New York City) [1]',\n",
       "  'October 31, 1941 ( 1941-10-31 ) (U.S.)'],\n",
       " 'Running time': '64 minutes',\n",
       " 'Country': 'United States',\n",
       " 'Language': 'English',\n",
       " 'Budget': '$950,000 [2]',\n",
       " 'Box office': '$1.3 million (est. United States/Canada rentals, 1941) [3]'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after we load the page, we inspect the page and found the tags that matchs our objective.\n",
    "info_movie = dumbo_page.find(class_ = \"infobox vevent\")\n",
    "info_movie_ = info_movie.find_all(\"tr\")\n",
    "\n",
    "movie = {}\n",
    "\n",
    "def get_content_value(row_data):\n",
    "    # I noticed that some pages have the tag \"b\" for multiple names/strings and other has the tag \"li\"\n",
    "    \n",
    "    if row_data.find(\"li\"):\n",
    "        return [li.get_text(\" \", strip = True).replace(\"\\xa0\", \" \") for li in row_data.find_all(\"li\")]\n",
    "    \n",
    "    \n",
    "    elif row_data.find(\"b\") or row_data.find(\"br\"):\n",
    "        return [br.get_text(\" \", strip = True).replace(\"\\xa0\", \" \") for br in row_data.find_all(\"a\")]\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        return row_data.get_text(\" \", strip = True).replace(\"\\xa0\", \" \")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for index, info in enumerate(info_movie_):\n",
    "    \n",
    "    if index == 0:\n",
    "        movie['title'] = info.get_text(\" \", strip = True)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        header = info.find('th')\n",
    "        if header:\n",
    "            content_key = info.find(\"th\").get_text(\" \", strip = True)\n",
    "            content_value = get_content_value(info.find(\"td\"))\n",
    "            movie[content_key] = content_value\n",
    "\n",
    "movie\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now that we acomplish for one example we can create a function to scraping all links*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tags(soup):\n",
    "    for tag in soup.find_all([\"sup\", \"span\"]):\n",
    "        tag.decompose()\n",
    "        \n",
    "\n",
    "\n",
    "def get_movies(url):\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    soup = bs(r.content)\n",
    "    \n",
    "    info_movie = soup.find(class_ = \"infobox vevent\")\n",
    "    info_movie_ = info_movie.find_all(\"tr\")\n",
    "    \n",
    "    movie_info = {}\n",
    "    \n",
    "    clean_tags(soup)\n",
    "    \n",
    "    for index, info in enumerate(info_movie_):\n",
    "\n",
    "        if index == 0:\n",
    "            movie_info['title'] = info.find(\"th\").get_text(\" \", strip = True)\n",
    "\n",
    "        \n",
    "        else:\n",
    "            header = info.find('th')\n",
    "            if header:\n",
    "                content_key = info.find(\"th\").get_text(\" \", strip = True)\n",
    "                content_key = info.find(\"th\").get_text(\" \", strip = True)\n",
    "                content_value = get_content_value(info.find(\"td\"))\n",
    "                movie_info[content_key] = content_value\n",
    "            \n",
    "    return movie_info\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zorro the Avenger\n",
      "'NoneType' object has no attribute 'find'\n",
      "The Sign of Zorro\n",
      "'NoneType' object has no attribute 'find'\n",
      "True-Life Adventures\n",
      "'NoneType' object has no attribute 'find_all'\n"
     ]
    }
   ],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_Walt_Disney_Pictures_films\"\n",
    "\n",
    "r = requests.get(url) # we get a request on the principal page\n",
    "soup = bs(r.content)\n",
    "\n",
    "movies = soup.select(\".wikitable.sortable i a\") # get only the link\n",
    "\n",
    "base_path = \"https://en.wikipedia.org/\"\n",
    "movie_info_list = []\n",
    "\n",
    "for index, movie in enumerate(movies):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        relative_path = movie['href']\n",
    "        title = movie['title']\n",
    "        full_path = base_path + relative_path\n",
    "        \n",
    "        movie_info_list.append(get_movies(full_path))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(movie.get_text())\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies collected: 438\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of movies collected: {len(movie_info_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the movie data\n",
    "\n",
    "import json\n",
    "\n",
    "def save_data(title, data):\n",
    "    with open(title, 'w', encoding = 'utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data('Disney_movies.json', movie_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
